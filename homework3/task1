#############################
data/1.csv
#############################
data/2.csv
#############################
data/3.csv
#############################
data/4.csv
#############################
data/5.csv
#############################
data/6.csv
#############################
data/7.csv
#############################
data/8.csv
#############################
data/9.csv
#############################
data/10.csv
#############################
data/11.csv
#############################
data/12.csv
fit##################
fit##################
fit##################
fit##################
fit##################
fit##################
#############################
data/13.csv
predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    1
dtype: int64
0    1
dtype: int64
[1 2 3 3 3 7 1 1 7 7 7 7 1 1 7 7 1 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
0.766666666667
             precision    recall  f1-score   support

          1       1.00      0.77      0.87        60
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.77      0.87        60

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 4 4]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         5
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 7 4]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         5
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    2
dtype: int64
0    7
dtype: int64
[3 7 7 7 7]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 7 2]
0.2
             precision    recall  f1-score   support

          2       1.00      0.20      0.33         5
          7       0.00      0.00      0.00         0

avg / total       1.00      0.20      0.33         5

predict#############################
GaussianNB(priors=None)
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 5 5]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         5
          5       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    3
dtype: int64
0    7
dtype: int64
[4 3 7 7 7 7 7 7 7 3 4 4 4 7 7 7 7 7 7 7 1 4 4 4 7 7 2]
0.0740740740741
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       1.00      0.07      0.14        27
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.07      0.14        27

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    3
dtype: int64
0    7
dtype: int64
[3 4 7 7 7 1 7 7 7 3 4 3 3 7 1 7 7 7 7 7 1 7 4 4 7 7 1]
0.148148148148
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       1.00      0.15      0.26        27
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.15      0.26        27

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    3
dtype: int64
0    7
dtype: int64
[5 3 7 7 7 7 1 1 1 3 4 4 4 3 7 7 7 1 1 1 7 3 4 4 2 7 3]
0.185185185185
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       1.00      0.19      0.31        27
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.19      0.31        27

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    3
dtype: int64
0    7
dtype: int64
[4 7 7 7 7 7 7 7 7 7 4 4 7 7 7 7 7 7 7 7 7 7 4 4 7 7 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00        27
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        27

predict#############################
GaussianNB(priors=None)
0    3
dtype: int64
0    7
dtype: int64
[3 4 6 7 7 7 7 7 7 4 4 4 4 7 7 7 7 7 7 7 7 4 4 4 4 7 5]
0.037037037037
             precision    recall  f1-score   support

          3       1.00      0.04      0.07        27
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.04      0.07        27

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    3
dtype: int64
0    1
dtype: int64
[3 1 7 7 1 1 1 1 7 1 4 4 1 1 1 7 7 7 7 7 7 1 5 5 1 1 7]
0.037037037037
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       1.00      0.04      0.07        27
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.04      0.07        27

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    4
dtype: int64
0    4
dtype: int64
[7 7 7 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]
0.948275862069
             precision    recall  f1-score   support

          4       1.00      0.95      0.97        58
          7       0.00      0.00      0.00         0

avg / total       1.00      0.95      0.97        58

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    5
dtype: int64
0    4
dtype: int64
[7 7 7 4 4 4 4 4 4 4 5]
0.0909090909091
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       1.00      0.09      0.17        11
          7       0.00      0.00      0.00         0

avg / total       1.00      0.09      0.17        11

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    5
dtype: int64
0    4
dtype: int64
[1 7 7 3 4 4 4 4 4 4 4]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    5
dtype: int64
0    4
dtype: int64
[7 1 7 3 3 4 4 4 3 4 4]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    5
dtype: int64
0    4
dtype: int64
[7 7 7 2 4 5 4 4 5 4 2]
0.181818181818
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       1.00      0.18      0.31        11
          7       0.00      0.00      0.00         0

avg / total       1.00      0.18      0.31        11

predict#############################
GaussianNB(priors=None)
0    5
dtype: int64
0    4
dtype: int64
[7 7 7 4 4 4 4 4 4 4 5]
0.0909090909091
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       1.00      0.09      0.17        11
          7       0.00      0.00      0.00         0

avg / total       1.00      0.09      0.17        11

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    5
dtype: int64
0    5
dtype: int64
[1 7 7 1 5 5 5 5 5 5 7]
0.545454545455
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          5       1.00      0.55      0.71        11
          7       0.00      0.00      0.00         0

avg / total       1.00      0.55      0.71        11

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    6
dtype: int64
0    7
dtype: int64
[7 7 3 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    6
dtype: int64
0    7
dtype: int64
[1 7 7 4]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    6
dtype: int64
0    7
dtype: int64
[3 7 7 7]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
GaussianNB(priors=None)
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 5]
0.0
             precision    recall  f1-score   support

          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    6
dtype: int64
0    1
dtype: int64
[1 1 1 7]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    7
dtype: int64
0    7
dtype: int64
[4 4 4 3 7 7 7 7 7 7 7 7 7 7 7 7 7 1 1 1 7 7 7 7 7 1 7 7 7 7 1 1 1 1 1 1 1
 1 1 7 7 1 7 7 7 7 7 7 7 7 7 7 7 1 1 7 7]
0.649122807018
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       1.00      0.65      0.79        57

avg / total       1.00      0.65      0.79        57

result:0.5
#############################
data/14.csv
predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    1
dtype: int64
0    1
dtype: int64
[1 1 1 7 7 7 1 1 1 1 1 1 1 1 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 7 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 7 1 1 1 1 1 1 1 1 1 1 1 1 1 7 1 1 1 1 1 1 1 7 1 1 1 1 1 1 1 7 1
 1 1 1 1 1 1 1 1 1 7 7 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
0.920454545455
             precision    recall  f1-score   support

          1       1.00      0.92      0.96       176
          7       0.00      0.00      0.00         0

avg / total       1.00      0.92      0.96       176

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
Series([], dtype: int64)
Series([], dtype: int64)
[1]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         1

avg / total       0.00      0.00      0.00         1

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
Series([], dtype: int64)
Series([], dtype: int64)
[6]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         1
          6       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         1

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
Series([], dtype: int64)
Series([], dtype: int64)
[1]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         1

avg / total       0.00      0.00      0.00         1

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
Series([], dtype: int64)
Series([], dtype: int64)
[2]
1.0
             precision    recall  f1-score   support

          2       1.00      1.00      1.00         1

avg / total       1.00      1.00      1.00         1

predict#############################
GaussianNB(priors=None)
Series([], dtype: int64)
Series([], dtype: int64)
[6]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         1
          6       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         1

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
Series([], dtype: int64)
Series([], dtype: int64)
[1]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         1

avg / total       0.00      0.00      0.00         1

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    3
dtype: int64
0    7
dtype: int64
[7 7 1 7 4 4 3 7 7 1 1 7 1 7 7 1 3 4 7 7 7 1 1 1 7 7 7 7 1 1 4 7 1 7 7 7 7
 7 7 7 7 1]
0.047619047619
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       1.00      0.05      0.09        42
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.05      0.09        42

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    3
dtype: int64
0    7
dtype: int64
[1 7 7 1 4 4 3 7 1 1 1 7 7 7 3 7 3 4 7 1 1 7 3 3 1 7 7 1 7 4 2 7 7 3 7 7 1
 7 7 7 7 1]
0.142857142857
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       1.00      0.14      0.25        42
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.14      0.25        42

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    3
dtype: int64
0    7
dtype: int64
[1 7 1 7 3 4 7 7 3 7 3 7 3 7 7 1 3 4 7 7 7 1 3 7 1 7 7 1 1 7 2 3 7 7 7 7 1
 7 7 7 7 3]
0.190476190476
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       1.00      0.19      0.32        42
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.19      0.32        42

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    3
dtype: int64
0    7
dtype: int64
[2 7 7 7 7 3 7 7 7 7 7 7 7 7 7 1 7 7 7 7 1 7 7 1 1 7 7 7 7 2 2 7 7 7 7 7 7
 7 7 7 1 2]
0.0238095238095
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       1.00      0.02      0.05        42
          7       0.00      0.00      0.00         0

avg / total       1.00      0.02      0.05        42

predict#############################
GaussianNB(priors=None)
0    3
dtype: int64
0    7
dtype: int64
[7 7 7 7 4 4 3 7 7 7 7 7 7 7 7 7 3 4 7 7 7 7 7 7 7 7 7 7 7 7 4 7 2 7 7 7 7
 7 7 7 7 6]
0.047619047619
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       1.00      0.05      0.09        42
          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.05      0.09        42

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    3
dtype: int64
0    7
dtype: int64
[1 7 7 7 7 4 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 1 7 7 7 7 1 1
 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00        42
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        42

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    4
dtype: int64
0    4
dtype: int64
[1 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]
0.979381443299
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       1.00      0.98      0.99        97

avg / total       1.00      0.98      0.99        97

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    5
dtype: int64
0    4
dtype: int64
[7 4 4 4 4 4 4 4 4 4 4 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        12
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        12

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    5
dtype: int64
0    4
dtype: int64
[1 7 4 4 4 4 4 4 4 4 4 5]
0.0833333333333
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       1.00      0.08      0.15        12
          7       0.00      0.00      0.00         0

avg / total       1.00      0.08      0.15        12

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    5
dtype: int64
0    4
dtype: int64
[7 2 4 4 4 3 7 2 4 4 4 6]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        12
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        12

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    5
dtype: int64
0    4
dtype: int64
[7 2 3 4 4 4 4 4 4 4 4 4]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        12
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        12

predict#############################
GaussianNB(priors=None)
0    5
dtype: int64
0    4
dtype: int64
[7 3 4 4 4 4 4 4 4 4 4 5]
0.0833333333333
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       1.00      0.08      0.15        12
          7       0.00      0.00      0.00         0

avg / total       1.00      0.08      0.15        12

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    5
dtype: int64
0    5
dtype: int64
[7 1 5 5 5 5 5 5 4 5 5 7]
0.666666666667
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       1.00      0.67      0.80        12
          7       0.00      0.00      0.00         0

avg / total       1.00      0.67      0.80        12

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 4 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    6
dtype: int64
0    1
1    2
dtype: int64
[1 1 2 4 2]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5

avg / total       0.00      0.00      0.00         5

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    6
dtype: int64
0    4
1    7
dtype: int64
[1 7 7 4 4]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    6
dtype: int64
0    7
dtype: int64
[7 7 2 3 7]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
GaussianNB(priors=None)
0    6
dtype: int64
0    4
1    7
dtype: int64
[7 7 4 4 5]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 4 7]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    7
dtype: int64
0    1
dtype: int64
[3 3 1 1 1 1 1 1 7 7 1 1 1 7 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 7 1 1 1
 1 7 1 1 7 1 7 7 7 7 1 1 7 1]
0.254901960784
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          7       1.00      0.25      0.41        51

avg / total       1.00      0.25      0.41        51

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    7
dtype: int64
0    1
dtype: int64
[3 1 7 3 1 1 1 1 1 2 1 7 7 7 7 1 7 1 7 1 1 7 1 7 1 7 1 7 1 1 7 2 1 1 1 1 1
 1 7 1 3 1 1 7 3 1 7 1 7 7 7]
0.352941176471
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          7       1.00      0.35      0.52        51

avg / total       1.00      0.35      0.52        51

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    7
dtype: int64
0    7
dtype: int64
[2 7 1 7 7 7 1 1 7 1 1 2 1 7 7 7 1 1 7 3 7 7 7 7 7 7 1 1 1 7 7 1 1 1 3 1 1
 1 7 1 1 7 7 7 3 3 1 7 3 3 1]
0.43137254902
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          7       1.00      0.43      0.60        51

avg / total       1.00      0.43      0.60        51

result:0.5
#############################
data/15.csv
predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    1
dtype: int64
0    7
dtype: int64
[1 2 7 2 2 2 3 7 7 7 7 4 4 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 7 7 7 1 7 7 1 7
 7 7 7 1 1 1 1 1 1 7 1 7 7 7 7 1 1 1 1 1 1 1 1 1 1 1 1 1 7 7 7 7 7 1 7 7 7
 7 7 7 7 1 1 1 7 7 7 7 7 7 7 7 1 1 7 7 7 7 7 7 7 1 7 7 7 7 7 1 7 1 1 1 7 7
 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 3 3 7 1 7 7 7 7 7 7 3 7 7 7 7 7 7
 1 1 7 7 7 7 7 7 3 3 3 3 2 2 1 7 7 7 7 2 7 7 7 3]
0.226744186047
             precision    recall  f1-score   support

          1       1.00      0.23      0.37       172
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.23      0.37       172

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    1
dtype: int64
0    7
dtype: int64
[1 3 4 7 3 7 7 7 7 7 7 4 4 7 7 3 7 7 7 7 1 3 7 7 7 1 1 1 1 1 7 1 1 1 1 1 1
 1 1 1 1 1 1 7 1 7 1 1 7 7 1 7 1 7 7 3 7 3 7 7 1 1 1 1 1 7 7 7 7 7 7 7 1 3
 7 7 1 1 1 1 7 1 7 3 1 3 1 7 1 1 1 7 7 7 7 3 7 1 1 1 1 7 7 7 1 1 7 1 7 7 7
 1 1 7 1 7 7 7 1 7 1 7 1 1 7 7 7 1 7 7 7 1 1 7 1 7 7 1 1 3 7 7 7 1 7 7 1 7
 1 1 1 7 1 7 1 3 7 1 7 7 7 7 7 7 7 3 7 7 1 7 1 2]
0.406976744186
             precision    recall  f1-score   support

          1       1.00      0.41      0.58       172
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.41      0.58       172

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    1
dtype: int64
0    1
dtype: int64
[1 1 7 7 1 4 1 1 1 1 1 4 7 7 1 1 1 7 1 1 1 1 1 7 7 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 7 3 3 3 3 3 3 3 7 3 7 7 1 1 1 1 1 1 1 1
 1 7 1 7 7 7 7 1 1 1 7 7 7 7 7 7 7 7 1 1 7 7 7 7 7 7 7 7 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 1 1 1 1 1 1 1 1 1 7 7 7 1 7 7 1 1 1 1
 1 1 7 1 1 1 1 7 1 3 3 3 7 7 7 7 7 3 7 7 7 7 7 1]
0.622093023256
             precision    recall  f1-score   support

          1       1.00      0.62      0.77       172
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.62      0.77       172

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    2
dtype: int64
0    1
dtype: int64
[3 3 1 7 7 7 7 7 1 1 1 1 2 2 1]
0.133333333333
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       1.00      0.13      0.24        15
          3       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.13      0.24        15

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    2
dtype: int64
0    7
dtype: int64
[7 1 7 7 7 7 7 1 3 7 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00        15
          3       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        15

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    2
dtype: int64
0    7
dtype: int64
[3 1 7 7 3 3 1 7 7 7 7 1 7 7 1]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00        15
          3       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        15

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    2
dtype: int64
0    7
dtype: int64
[2 2 6 7 7 7 2 7 7 1 7 7 3 3 7]
0.2
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       1.00      0.20      0.33        15
          3       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.20      0.33        15

predict#############################
GaussianNB(priors=None)
0    2
dtype: int64
0    7
dtype: int64
[3 3 7 7 2 2 7 2 7 7 7 7 2 2 6]
0.333333333333
             precision    recall  f1-score   support

          2       1.00      0.33      0.50        15
          3       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.33      0.50        15

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 7 7 7 7 7 7 7 7 3 7 7 7]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00        15
          3       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        15

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    3
dtype: int64
0    4
dtype: int64
[1 7 7 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 7 7 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00        26
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        26

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    3
dtype: int64
0    4
dtype: int64
[1 7 3 4 4 3 4 4 4 4 4 4 4 4 4 7 4 4 4 7 7 7 7 7 6 3]
0.115384615385
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       1.00      0.12      0.21        26
          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.12      0.21        26

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    3
dtype: int64
0    7
dtype: int64
[7 7 7 3 3 3 3 4 4 4 4 4 4 4 3 3 3 4 4 7 7 7 7 7 7 7]
0.269230769231
             precision    recall  f1-score   support

          3       1.00      0.27      0.42        26
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.27      0.42        26

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    3
dtype: int64
0    4
dtype: int64
[7 7 7 4 3 7 3 4 4 4 4 4 4 4 4 4 4 4 4 7 7 7 7 7 7 7]
0.0769230769231
             precision    recall  f1-score   support

          3       1.00      0.08      0.14        26
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.08      0.14        26

predict#############################
GaussianNB(priors=None)
0    3
dtype: int64
0    4
dtype: int64
[7 7 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 7 7 7 7 7 5]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00        26
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        26

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    3
dtype: int64
0    7
dtype: int64
[7 7 7 3 5 7 5 4 4 4 4 4 4 4 5 5 5 4 4 7 7 7 7 7 7 7]
0.0384615384615
             precision    recall  f1-score   support

          3       1.00      0.04      0.07        26
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.04      0.07        26

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    4
dtype: int64
0    4
dtype: int64
[4 7 7 4 4 4 3 7 7 4 2 7 7 7 7 7 7 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]
0.775862068966
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       1.00      0.78      0.87        58
          7       0.00      0.00      0.00         0

avg / total       1.00      0.78      0.87        58

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    5
dtype: int64
0    4
dtype: int64
[4 4 4 4 4 4 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    5
dtype: int64
0    4
dtype: int64
[4 4 4 4 2 4 7 7 7 7 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    5
dtype: int64
0    4
dtype: int64
[4 4 4 4 4 4 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    5
dtype: int64
0    4
dtype: int64
[4 4 4 4 4 4 6 7 7 7 7]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
GaussianNB(priors=None)
0    5
dtype: int64
0    4
dtype: int64
[4 4 4 4 4 4 7 7 7 7 5]
0.0909090909091
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       1.00      0.09      0.17        11
          7       0.00      0.00      0.00         0

avg / total       1.00      0.09      0.17        11

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    5
dtype: int64
0    4
1    7
dtype: int64
[4 4 4 4 4 3 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    6
dtype: int64
0    4
dtype: int64
[4 4 4]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3

avg / total       0.00      0.00      0.00         3

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    6
dtype: int64
0    4
dtype: int64
[4 4 4]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3

avg / total       0.00      0.00      0.00         3

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    6
dtype: int64
0    4
dtype: int64
[3 4 4]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3

avg / total       0.00      0.00      0.00         3

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    6
dtype: int64
0    4
dtype: int64
[4 4 4]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3

avg / total       0.00      0.00      0.00         3

predict#############################
GaussianNB(priors=None)
0    6
dtype: int64
0    4
dtype: int64
[4 4 5]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3

avg / total       0.00      0.00      0.00         3

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    6
dtype: int64
0    3
dtype: int64
[3 3 7]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         3

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    7
dtype: int64
0    7
dtype: int64
[4 4 4 4 4 4 4 7 7 7 7 7 7 7 4 4 4 4 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]
0.810344827586
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          7       1.00      0.81      0.90        58

avg / total       1.00      0.81      0.90        58

result:0.375

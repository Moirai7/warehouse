Use scipy logsumexp().
#############################
data/1.csv
#############################
data/2.csv
#############################
data/3.csv
#############################
data/4.csv
#############################
data/5.csv
#############################
data/6.csv
#############################
data/7.csv
#############################
data/8.csv
#############################
data/9.csv
#############################
data/10.csv
#############################
data/11.csv
#############################
data/12.csv
fit##################
fit##################
fit##################
fit##################
fit##################
fit##################
#############################
data/13.csv
predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    1
dtype: int64
0    1
dtype: int64
[1 1 3 3 3 7 1 7 7 7 7 7 1 1 7 7 1 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
0.766666666667
             precision    recall  f1-score   support

          1       1.00      0.77      0.87        60
          3       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.77      0.87        60

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    2
dtype: int64
0    7
dtype: int64
[7 1 7 7 2]
0.2
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       1.00      0.20      0.33         5
          7       0.00      0.00      0.00         0

avg / total       1.00      0.20      0.33         5

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    2
dtype: int64
0    7
dtype: int64
[7 7 3 7 4]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 7 2]
0.2
             precision    recall  f1-score   support

          2       1.00      0.20      0.33         5
          7       0.00      0.00      0.00         0

avg / total       1.00      0.20      0.33         5

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 7 2]
0.2
             precision    recall  f1-score   support

          2       1.00      0.20      0.33         5
          7       0.00      0.00      0.00         0

avg / total       1.00      0.20      0.33         5

predict#############################
GaussianNB(priors=None)
0    2
dtype: int64
0    2
1    5
dtype: int64
[6 2 2 5 5]
0.4
             precision    recall  f1-score   support

          2       1.00      0.40      0.57         5
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0

avg / total       1.00      0.40      0.57         5

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    3
dtype: int64
0    7
dtype: int64
[3 3 7 7 7 7 7 7 7 3 4 4 3 3 7 7 7 7 7 7 7 7 3 3 7 7 6]
0.259259259259
             precision    recall  f1-score   support

          3       1.00      0.26      0.41        27
          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.26      0.41        27

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    3
dtype: int64
0    7
dtype: int64
[1 4 7 7 7 7 7 7 7 3 4 4 4 3 1 7 7 7 7 7 3 4 4 4 2 3 7]
0.148148148148
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       1.00      0.15      0.26        27
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.15      0.26        27

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    3
dtype: int64
0    1
dtype: int64
[3 4 7 7 7 7 1 1 1 7 4 4 4 1 1 7 1 1 1 1 1 4 5 5 7 1 2]
0.037037037037
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         0
          3       1.00      0.04      0.07        27
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.04      0.07        27

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    3
dtype: int64
0    7
dtype: int64
[4 4 7 7 7 7 7 7 7 7 4 4 4 7 7 7 7 7 7 7 7 7 7 4 7 7 7]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00        27
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        27

predict#############################
GaussianNB(priors=None)
0    3
dtype: int64
0    6
dtype: int64
[2 5 5 6 6 6 6 6 6 6 5 5 5 6 6 6 6 6 6 6 6 5 5 5 5 6 5]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00        27
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        27

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    3
dtype: int64
0    7
dtype: int64
[5 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 7 7 1 7 5 5 5 7 7 7]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00        27
          5       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        27

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    4
dtype: int64
0    4
dtype: int64
[7 7 7 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 3 4 4 4 4]
0.896551724138
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          4       1.00      0.90      0.95        58
          7       0.00      0.00      0.00         0

avg / total       1.00      0.90      0.95        58

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    5
dtype: int64
0    3
dtype: int64
[7 7 7 7 3 4 3 3 3 3 5]
0.0909090909091
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       1.00      0.09      0.17        11
          7       0.00      0.00      0.00         0

avg / total       1.00      0.09      0.17        11

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    5
dtype: int64
0    4
dtype: int64
[1 3 1 4 4 4 4 4 4 3 5]
0.0909090909091
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       1.00      0.09      0.17        11

avg / total       1.00      0.09      0.17        11

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    5
dtype: int64
0    3
dtype: int64
[1 7 1 1 3 3 3 3 5 3 5]
0.181818181818
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          5       1.00      0.18      0.31        11
          7       0.00      0.00      0.00         0

avg / total       1.00      0.18      0.31        11

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    5
dtype: int64
0    4
1    7
dtype: int64
[7 7 7 7 4 4 4 4 4 7 5]
0.0909090909091
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       1.00      0.09      0.17        11
          7       0.00      0.00      0.00         0

avg / total       1.00      0.09      0.17        11

predict#############################
GaussianNB(priors=None)
0    5
dtype: int64
0    5
dtype: int64
[6 2 2 5 5 5 5 5 5 5 5]
0.727272727273
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          5       1.00      0.73      0.84        11
          6       0.00      0.00      0.00         0

avg / total       1.00      0.73      0.84        11

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    6
dtype: int64
0    7
dtype: int64
[7 1 7 3]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 7]
0.0
             precision    recall  f1-score   support

          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
GaussianNB(priors=None)
0    6
dtype: int64
0    2
dtype: int64
[2 2 6 5]
0.25
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       1.00      0.25      0.40         4

avg / total       1.00      0.25      0.40         4

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 7]
0.0
             precision    recall  f1-score   support

          6       0.00      0.00      0.00         4
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         4

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    7
dtype: int64
0    7
dtype: int64
[7 4 3 3 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 7 7 7 7 7 7 1 7 7 7 7 1 1 7 7 1 1 1
 1 1 7 7 1 7 7 7 7 7 7 7 7 7 7 7 3 1 7 7]
0.736842105263
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       1.00      0.74      0.85        57

avg / total       1.00      0.74      0.85        57

result:0.5
#############################
data/14.csv
predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    1
dtype: int64
0    3
dtype: int64
[1 3 3 3 7 3 3 3 3 3 3 3 3 7 3 3 3 3 7 3 3 3 3 1 3 1 7 3 3 3 3 3 3 7 3 3 3
 3 3 3 3 3 3 3 1 7 3 3 3 1 3 3 7 3 3 3 3 3 3 3 3 3 3 1 3 3 7 1 3 3 3 7 7 1
 3 3 3 7 3 3 3 3 3 3 3 3 3 3 3 3 1 7 3 3 3 3 3 3 7 7 7 3 7 3 3 3 3 3 3 7 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 7 3 3 3 3 3 3 3 3 3 3 7 3 3 3 3 3 3 1]
0.0568181818182
             precision    recall  f1-score   support

          1       1.00      0.06      0.11       176
          3       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.06      0.11       176

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    1
dtype: int64
0    1
dtype: int64
[4 1 7 1 1 1 1 1 1 1 1 7 7 1 1 1 1 1 7 7 1 1 7 7 1 1 1 1 7 3 1 1 1 1 1 7 1
 1 1 7 1 1 1 1 1 1 1 1 1 1 1 7 7 1 7 1 1 7 1 1 1 1 3 1 1 1 7 7 1 1 7 1 1 7
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 1 1 1 1 7 7 1 1 1 1 7 7 7 7 7 1 1 3 7 7 7 7
 7 1 1 1 1 1 7 1 1 1 1 1 7 1 1 1 7 1 1 7 1 1 1 7 7 1 1 1 1 7 1 7 1 1 1 7 1
 1 1 1 1 1 2 1 1 1 1 7 1 7 1 1 7 7 1 1 7 1 1 1 7 1 1 1 7]
0.704545454545
             precision    recall  f1-score   support

          1       1.00      0.70      0.83       176
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.70      0.83       176

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
Series([], dtype: int64)
Series([], dtype: int64)
[1]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         1

avg / total       0.00      0.00      0.00         1

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
Series([], dtype: int64)
Series([], dtype: int64)
[1]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         1

avg / total       0.00      0.00      0.00         1

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
Series([], dtype: int64)
Series([], dtype: int64)
[7]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         1
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         1

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
Series([], dtype: int64)
Series([], dtype: int64)
[1]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00         1

avg / total       0.00      0.00      0.00         1

predict#############################
GaussianNB(priors=None)
Series([], dtype: int64)
Series([], dtype: int64)
[7]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         1
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         1

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
Series([], dtype: int64)
Series([], dtype: int64)
[7]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         1
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         1

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    3
dtype: int64
0    3
dtype: int64
[7 7 3 3 3 3 3 7 7 3 3 7 3 3 3 3 3 3 3 3 7 7 3 3 3 3 3 3 3 3 7 3 1 7 7 7 7
 7 7 7 7 1]
0.571428571429
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       1.00      0.57      0.73        42
          7       0.00      0.00      0.00         0

avg / total       1.00      0.57      0.73        42

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    4
dtype: int64
0    4
dtype: int64
[3 3 3 3 4 4 4 4 3 7 7 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 7 3 3 4 4 7 7 7 7 4 4
 4 4 4 4 4 4 7 7 4 4 4 4 4 4 3 3 3 4 4 4 4 4 4]
0.79381443299
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          4       1.00      0.79      0.89        97
          7       0.00      0.00      0.00         0

avg / total       1.00      0.79      0.89        97

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    5
dtype: int64
0    3
dtype: int64
[3 3 3 3 3 3 3 3 3 3 3 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        12

avg / total       0.00      0.00      0.00        12

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    5
dtype: int64
0    4
dtype: int64
[1 4 4 4 4 4 4 4 4 4 4 5]
0.0833333333333
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       1.00      0.08      0.15        12

avg / total       1.00      0.08      0.15        12

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    5
dtype: int64
0    4
dtype: int64
[7 2 5 4 4 4 3 3 4 5 4 4]
0.166666666667
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       1.00      0.17      0.29        12
          7       0.00      0.00      0.00         0

avg / total       1.00      0.17      0.29        12

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    5
dtype: int64
0    4
dtype: int64
[7 7 7 4 7 4 4 4 4 4 4 7]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        12
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        12

predict#############################
GaussianNB(priors=None)
0    5
dtype: int64
0    5
dtype: int64
[2 5 5 5 5 5 5 5 5 5 5 5]
0.916666666667
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          5       1.00      0.92      0.96        12

avg / total       1.00      0.92      0.96        12

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    6
dtype: int64
0    3
1    7
dtype: int64
[7 7 3 3 2]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    6
dtype: int64
0    4
1    7
dtype: int64
[7 7 4 4 5]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    6
dtype: int64
0    3
dtype: int64
[7 3 3 4 5]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 4 7]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
GaussianNB(priors=None)
0    6
dtype: int64
0    5
1    6
dtype: int64
[2 6 6 5 5]
0.4
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       1.00      0.40      0.57         5

avg / total       1.00      0.40      0.57         5

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    6
dtype: int64
0    7
dtype: int64
[7 7 7 5 7]
0.0
             precision    recall  f1-score   support

          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         5
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         5

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    7
dtype: int64
0    3
dtype: int64
[3 3 3 3 3 3 3 3 7 7 3 7 1 7 7 7 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 7 3 3 3 3
 7 7 3 7 7 3 3 3 3 7 3 3 3 1]
0.235294117647
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          7       1.00      0.24      0.38        51

avg / total       1.00      0.24      0.38        51

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    7
dtype: int64
0    7
dtype: int64
[4 1 1 1 7 1 7 1 7 1 1 7 7 7 7 1 1 7 7 7 1 1 7 1 7 7 1 1 7 3 7 1 1 7 7 1 1
 7 7 7 7 1 7 7 7 1 7 1 7 1 1]
0.509803921569
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       1.00      0.51      0.68        51

avg / total       1.00      0.51      0.68        51

result:0.625
#############################
data/15.csv
predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    1
dtype: int64
0    7
dtype: int64
[1 1 7 2 2 3 3 7 7 7 7 4 4 7 7 7 7 3 7 7 1 7 7 7 1 7 7 7 1 7 7 7 1 1 7 1 7
 7 7 1 1 1 1 1 1 1 7 1 7 7 7 7 1 1 1 1 1 1 1 1 1 1 1 1 1 7 7 7 7 7 1 7 7 1
 7 7 7 1 1 1 1 7 7 1 7 7 3 3 3 1 1 7 7 7 7 7 3 7 1 3 3 7 7 1 1 3 1 1 7 7 7
 1 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 1 1 7 7 3 3 1 1 7 7 7 7 7 7 7 7 7 7 7 7 7
 1 1 7 7 7 7 7 7 3 3 2 2 2 7 1 7 7 7 7 7 1 1 7 7]
0.313953488372
             precision    recall  f1-score   support

          1       1.00      0.31      0.48       172
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.31      0.48       172

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    1
dtype: int64
0    1
dtype: int64
[1 4 4 4 3 4 7 1 7 7 1 3 4 7 3 4 2 7 1 7 1 7 7 1 7 1 1 1 1 1 1 7 1 1 7 7 7
 1 1 1 1 1 7 7 7 1 1 1 7 7 7 1 7 1 1 1 7 3 1 3 3 1 1 1 7 7 1 7 1 3 1 7 7 1
 7 7 1 1 7 7 1 7 1 3 1 1 1 1 1 3 7 7 3 3 7 1 7 1 4 7 7 7 1 7 7 1 7 1 7 7 1
 1 7 1 1 7 7 7 1 1 7 7 7 7 7 7 7 1 1 7 7 1 1 1 1 1 3 7 1 1 1 1 3 7 7 1 1 7
 7 1 7 7 1 7 1 7 7 1 1 1 3 1 3 7 7 7 1 7 1 1 7 2]
0.447674418605
             precision    recall  f1-score   support

          1       1.00      0.45      0.62       172
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.45      0.62       172

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    2
dtype: int64
0    1
dtype: int64
[2 1 1 1 1 1 7 1 1 1 1 1 2 2 7]
0.2
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       1.00      0.20      0.33        15
          7       0.00      0.00      0.00         0

avg / total       1.00      0.20      0.33        15

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    2
dtype: int64
0    7
dtype: int64
[4 1 1 6 7 7 1 7 7 7 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00        15
          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        15

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    2
dtype: int64
0    7
dtype: int64
[1 3 7 7 1 3 7 7 7 7 7 1 1 1 7]
0.0
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          2       0.00      0.00      0.00        15
          3       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        15

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    2
dtype: int64
0    7
dtype: int64
[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00        15
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        15

predict#############################
GaussianNB(priors=None)
0    2
dtype: int64
0    2
dtype: int64
[2 2 6 6 2 2 2 2 6 6 6 2 2 2 6]
0.6
             precision    recall  f1-score   support

          2       1.00      0.60      0.75        15
          6       0.00      0.00      0.00         0

avg / total       1.00      0.60      0.75        15

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    3
dtype: int64
0    4
dtype: int64
[1 7 7 4 4 7 4 4 4 4 4 4 4 4 4 3 4 4 4 7 7 7 7 7 7 7]
0.0384615384615
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       1.00      0.04      0.07        26
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.04      0.07        26

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    3
dtype: int64
0    4
dtype: int64
[1 7 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 7 1 7 7 7 7]
0.0384615384615
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       1.00      0.04      0.07        26
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.04      0.07        26

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    3
dtype: int64
0    4
dtype: int64
[7 7 7 4 3 3 4 4 4 4 4 4 4 4 4 4 3 3 4 7 1 7 7 7 7 3]
0.192307692308
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          3       1.00      0.19      0.32        26
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.19      0.32        26

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    3
dtype: int64
0    7
dtype: int64
[7 7 7 7 7 7 4 4 4 4 4 4 4 4 4 4 4 7 4 7 7 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00        26
          4       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        26

predict#############################
GaussianNB(priors=None)
0    3
dtype: int64
0    5
dtype: int64
[6 2 2 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6]
0.0
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00        26
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        26

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    3
dtype: int64
0    7
dtype: int64
[7 7 7 3 5 5 5 3 3 3 7 7 3 3 5 5 5 7 3 7 7 7 7 7 7 7]
0.269230769231
             precision    recall  f1-score   support

          3       1.00      0.27      0.42        26
          5       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       1.00      0.27      0.42        26

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    4
dtype: int64
0    4
dtype: int64
[4 7 7 4 4 3 3 7 7 7 7 7 7 7 7 7 7 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]
0.741379310345
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          4       1.00      0.74      0.85        58
          7       0.00      0.00      0.00         0

avg / total       1.00      0.74      0.85        58

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    5
dtype: int64
0    4
dtype: int64
[4 4 4 4 4 4 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    5
dtype: int64
0    4
dtype: int64
[4 4 4 4 3 4 5 7 7 7 2]
0.0909090909091
             precision    recall  f1-score   support

          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       1.00      0.09      0.17        11
          7       0.00      0.00      0.00         0

avg / total       1.00      0.09      0.17        11

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    5
dtype: int64
0    4
dtype: int64
[4 4 4 4 4 4 7 7 7 7 3]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    5
dtype: int64
0    7
dtype: int64
[7 4 4 4 4 4 7 7 7 7 7]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00        11
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00        11

predict#############################
GaussianNB(priors=None)
0    5
dtype: int64
0    5
dtype: int64
[5 5 5 5 5 5 6 6 6 6 5]
0.636363636364
             precision    recall  f1-score   support

          5       1.00      0.64      0.78        11
          6       0.00      0.00      0.00         0

avg / total       1.00      0.64      0.78        11

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    6
dtype: int64
0    4
dtype: int64
[4 4 5]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3

avg / total       0.00      0.00      0.00         3

predict#############################
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
0    6
dtype: int64
0    4
dtype: int64
[4 4 5]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3

avg / total       0.00      0.00      0.00         3

predict#############################
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
0    6
dtype: int64
0    3
dtype: int64
[3 3 5]
0.0
             precision    recall  f1-score   support

          3       0.00      0.00      0.00         0
          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3

avg / total       0.00      0.00      0.00         3

predict#############################
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0    6
dtype: int64
0    7
dtype: int64
[7 4 7]
0.0
             precision    recall  f1-score   support

          4       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         3

predict#############################
GaussianNB(priors=None)
0    6
dtype: int64
0    5
dtype: int64
[5 5 5]
0.0
             precision    recall  f1-score   support

          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3

avg / total       0.00      0.00      0.00         3

predict#############################
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best')
0    6
dtype: int64
0    5
dtype: int64
[5 5 7]
0.0
             precision    recall  f1-score   support

          5       0.00      0.00      0.00         0
          6       0.00      0.00      0.00         3
          7       0.00      0.00      0.00         0

avg / total       0.00      0.00      0.00         3

predict#############################
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0    7
dtype: int64
0    7
dtype: int64
[4 4 4 4 4 4 4 7 7 7 7 7 7 7 4 4 4 4 7 7 7 7 1 7 7 7 1 7 7 7 7 7 7 7 7 7 7
 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 7 7 7 7]
0.758620689655
             precision    recall  f1-score   support

          1       0.00      0.00      0.00         0
          4       0.00      0.00      0.00         0
          7       1.00      0.76      0.86        58

avg / total       1.00      0.76      0.86        58

result:0.625
